#!/usr/bin/env python3
'''''''''''''''''''''''
COPYLEFT LESTERRRY, 2020
'''''''''''''''''''''''
#This script generates text based on 'model.bin' file, retrieved from learning.
#Make sure file is located in script directory and is readable.
#Serve -o argument to simply print predicrion
#Serve -p argument if picture is needed
import sys
import os
import pickle
from collections import Counter
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pic #Comment this if you're not going to generate pics

__location__ = os.path.realpath(
    os.path.join(os.getcwd(), os.path.dirname(__file__)))

#Replace this with 'CtI' dict retrieved while learning
CTI = {' ': 0, 'Ð¾': 1, 'Ð°': 2, 'Ðµ': 3, 'Ñ‚': 4, 'Ð¸': 5, 'Ð½': 6, 'Ñ': 7, 'Ð»': 8, 'Ñ€': 9, 'Ð²': 10, 'Ðº': 11, 'Ð¼': 12, 'Ð´': 13, 'Ñƒ': 14, 'Ð¿': 15, 'ÑŒ': 16, 'Ñ': 17, ',': 18, 'Ñ‹': 19, 'Ð±': 20, 'Ñ‡': 21, '.': 22, 'Ð¹': 23, 'Ð³': 24, 'Ð·': 25, 'Ñˆ': 26, 'Ð¶': 27, 'Ñ…': 28, 'ÑŽ': 29, '?': 30, '-': 31, '6': 32, 'Ð': 33, '1': 34, 'Ñ†': 35, 'Ðš': 36, 'Ð¡': 37, 'Ð': 38, 'Ñ': 39, 'Ð’': 40, 'Ðž': 41, 'ÐŸ': 42, '8': 43, 'Ð•': 44, 'Ð¢': 45, ':': 46, 'Ñ‰': 47, 'Ð˜': 48, 'Ðœ': 49, '9': 50, '0': 51, 'Ð”': 52, 'Ñ‘': 53, 'Ñ„': 54, 'Ð›': 55, '!': 56, '7': 57, 'Ð ': 58, '3': 59, '2': 60, 'Ð¯': 61, 'Ð£': 62, 'Ð“': 63, 'Ð‘': 64, '5': 65, '4': 66, 'Ð§': 67, 'Ð—': 68, 'Ð¥': 69, 'Ð¨': 70, 'Ð¬': 71, 'Ð«': 72, 'Ð­': 73, 'Ð–': 74, 'Ð™': 75, 'ÑŠ': 76, 'Ð¤': 77, 'Ð®': 78, 'Ð¦': 79, 'Ð©': 80, 'Ð': 81, 'Ñ˜': 82, 'Îž': 83, 'Ðª': 84, 'ÙŠ': 85, 'Ù†': 86, 'Ù…': 87, 'Í…': 88, 'r': 89, 'Ñ™': 90, 'ãƒ½': 91, 's': 92, 'p': 93, 'Ù„': 94, 'n': 95, 'a': 96, 'ã„›': 97, 'ã„—': 98, 'ã„™': 99, 'Ø±': 100, 'Ø§': 101, 'Ù': 102, 'Ù‡': 103, 'à½€': 104, 'Ê–': 105, 'C': 106, 'ã‚¤': 107, 'ï¾‰': 108, 'ï¼¹': 109, 'ãƒ¼': 110, 'Ø¬': 111, 'Ù‰': 112, 'Ø¥': 113, 'Ø´': 114, 'Ø¡': 115, 'Øª': 116, 'Ø¹': 117, 'Ùƒ': 118, 'Ø£': 119, 'Ø¤': 120, 'Ø³': 121, 'Ï€': 122, 'Å¼': 123, 'Ñš': 124, 'ÑŸ': 125, 'ð“‚º': 126, 'Y': 127, 'L': 128, 'O': 129, 'N': 130, 'E': 131, 'D': 132, 'e': 133, 'k': 134, 't': 135, 'o': 136, 'ãƒŽ': 137, 'ãƒˆ': 138, 'ä»': 139, 'ãƒŸ': 140, 'åœŸ': 141, 'å½¡': 142, 'Ñ¼': 143, '\n': 144}
#Replace this with 'ItC' dict retrieved while learning
ITC = {0: ' ', 1: 'Ð¾', 2: 'Ð°', 3: 'Ðµ', 4: 'Ñ‚', 5: 'Ð¸', 6: 'Ð½', 7: 'Ñ', 8: 'Ð»', 9: 'Ñ€', 10: 'Ð²', 11: 'Ðº', 12: 'Ð¼', 13: 'Ð´', 14: 'Ñƒ', 15: 'Ð¿', 16: 'ÑŒ', 17: 'Ñ', 18: ',', 19: 'Ñ‹', 20: 'Ð±', 21: 'Ñ‡', 22: '.', 23: 'Ð¹', 24: 'Ð³', 25: 'Ð·', 26: 'Ñˆ', 27: 'Ð¶', 28: 'Ñ…', 29: 'ÑŽ', 30: '?', 31: '-', 32: '6', 33: 'Ð', 34: '1', 35: 'Ñ†', 36: 'Ðš', 37: 'Ð¡', 38: 'Ð', 39: 'Ñ', 40: 'Ð’', 41: 'Ðž', 42: 'ÐŸ', 43: '8', 44: 'Ð•', 45: 'Ð¢', 46: ':', 47: 'Ñ‰', 48: 'Ð˜', 49: 'Ðœ', 50: '9', 51: '0', 52: 'Ð”', 53: 'Ñ‘', 54: 'Ñ„', 55: 'Ð›', 56: '!', 57: '7', 58: 'Ð ', 59: '3', 60: '2', 61: 'Ð¯', 62: 'Ð£', 63: 'Ð“', 64: 'Ð‘', 65: '5', 66: '4', 67: 'Ð§', 68: 'Ð—', 69: 'Ð¥', 70: 'Ð¨', 71: 'Ð¬', 72: 'Ð«', 73: 'Ð­', 74: 'Ð–', 75: 'Ð™', 76: 'ÑŠ', 77: 'Ð¤', 78: 'Ð®', 79: 'Ð¦', 80: 'Ð©', 81: 'Ð', 82: 'Ñ˜', 83: 'Îž', 84: 'Ðª', 85: 'ÙŠ', 86: 'Ù†', 87: 'Ù…', 88: 'Í…', 89: 'r', 90: 'Ñ™', 91: 'ãƒ½', 92: 's', 93: 'p', 94: 'Ù„', 95: 'n', 96: 'a', 97: 'ã„›', 98: 'ã„—', 99: 'ã„™', 100: 'Ø±', 101: 'Ø§', 102: 'Ù', 103: 'Ù‡', 104: 'à½€', 105: 'Ê–', 106: 'C', 107: 'ã‚¤', 108: 'ï¾‰', 109: 'ï¼¹', 110: 'ãƒ¼', 111: 'Ø¬', 112: 'Ù‰', 113: 'Ø¥', 114: 'Ø´', 115: 'Ø¡', 116: 'Øª', 117: 'Ø¹', 118: 'Ùƒ', 119: 'Ø£', 120: 'Ø¤', 121: 'Ø³', 122: 'Ï€', 123: 'Å¼', 124: 'Ñš', 125: 'ÑŸ', 126: 'ð“‚º', 127: 'Y', 128: 'L', 129: 'O', 130: 'N', 131: 'E', 132: 'D', 133: 'e', 134: 'k', 135: 't', 136: 'o', 137: 'ãƒŽ', 138: 'ãƒˆ', 139: 'ä»', 140: 'ãƒŸ', 141: 'åœŸ', 142: 'å½¡', 143: 'Ñ¼', 144: '\n'}

#Replace this with prediction length you want
PRED_LEN = 130

file = open(os.path.join(__location__, 'model1000c.bin'), "rb")

class TextRNN(nn.Module):
    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):
        super(TextRNN, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.embedding_size = embedding_size
        self.n_layers = n_layers
        self.encoder = nn.Embedding(self.input_size, self.embedding_size)
        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)
        self.dropout = nn.Dropout(0.2)
        self.fc = nn.Linear(self.hidden_size, self.input_size)
    def forward(self, x, hidden):
        x = self.encoder(x).squeeze(2)
        out, (ht1, ct1) = self.lstm(x, hidden)
        out = self.dropout(out)
        x = self.fc(out)
        return x, (ht1, ct1)
    def init_hidden(self, batch_size=1):
        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),
               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))

def evaluate(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):
    hidden = model.init_hidden()
    idx_input = [char_to_idx[char] for char in start_text]
    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)
    predicted_text = start_text

    _, hidden = model(train, hidden)

    inp = train[-1].view(-1, 1, 1)
    for i in range(prediction_len):
        output, hidden = model(inp.to(device), hidden)
        output_logits = output.cpu().data.view(-1)
        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()
        top_index = np.random.choice(len(char_to_idx), p=p_next)
        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)
        predicted_char = idx_to_char[top_index]
        predicted_text += predicted_char
    return predicted_text

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
mod = torch.load(file, map_location=device)
mod.eval()

def textev():
    text = (evaluate(
            mod,
            CTI,
            ITC,
            temp=0.3,
            prediction_len=PRED_LEN,
            start_text=' '
            )
        )
    text = text.split(' ')
    text = text[1:-1]
    text = ' '.join(text)
    text = text.lower().capitalize()
    return text
if '-o' in sys.argv:
    print(textev())
elif '-p' in sys.argv:
    if '-c' in sys.argv:
        i = 0
        while(True):
            #print(i)
            i += 1
            #text = (evaluate(mod, CTI, ITC, temp=0.3, prediction_len=PRED_LEN, start_text=' '))
            t = textev()
            print("\r>>", i, t, end='')
            pic.draw(textev())
    else:
        pic.draw(textev())

#!/usr/bin/env python3
'''''''''''''''''''''''
COPYLEFT LESTERRRY, 2020
'''''''''''''''''''''''
#This script generates text based on 'model.bin' file, retrieved from learning.
#Make sure file is located in script directory and is readable.
#Serve -o argument to simply print predicrion
#Serve -p argument if picture is needed
import sys
import os
import pickle
from collections import Counter
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pic #Comment this if you're not going to generate pics

__location__ = os.path.realpath(
    os.path.join(os.getcwd(), os.path.dirname(__file__)))

#Replace this with 'CtI' dict retrieved while learning
CTI = {' ': 0, '–æ': 1, '–∞': 2, '–µ': 3, '—Ç': 4, '–∏': 5, '–Ω': 6, '—Å': 7, '–ª': 8, '—Ä': 9, '–≤': 10, '–∫': 11, '–º': 12, '–¥': 13, '—É': 14, '–ø': 15, '—å': 16, '—è': 17, ',': 18, '—ã': 19, '–±': 20, '—á': 21, '.': 22, '–π': 23, '–≥': 24, '–∑': 25, '—à': 26, '–∂': 27, '—Ö': 28, '—é': 29, '?': 30, '-': 31, '6': 32, '–ê': 33, '1': 34, '—Ü': 35, '–ö': 36, '–°': 37, '–ù': 38, '—ç': 39, '–í': 40, '–û': 41, '–ü': 42, '8': 43, '–ï': 44, '–¢': 45, ':': 46, '—â': 47, '–ò': 48, '–ú': 49, '9': 50, '0': 51, '–î': 52, '—ë': 53, '—Ñ': 54, '–õ': 55, '!': 56, '7': 57, '–†': 58, '3': 59, '2': 60, '–Ø': 61, '–£': 62, '–ì': 63, '–ë': 64, '5': 65, '4': 66, '–ß': 67, '–ó': 68, '–•': 69, '–®': 70, '–¨': 71, '–´': 72, '–≠': 73, '–ñ': 74, '–ô': 75, '—ä': 76, '–§': 77, '–Æ': 78, '–¶': 79, '–©': 80, '–Å': 81, '—ò': 82, 'Œû': 83, '–™': 84, 'Ÿä': 85, 'ŸÜ': 86, 'ŸÖ': 87, 'ÕÖ': 88, 'r': 89, '—ô': 90, '„ÉΩ': 91, 's': 92, 'p': 93, 'ŸÑ': 94, 'n': 95, 'a': 96, '„Ñõ': 97, '„Ñó': 98, '„Ñô': 99, 'ÿ±': 100, 'ÿß': 101, 'ŸÅ': 102, 'Ÿá': 103, '‡ΩÄ': 104, ' ñ': 105, 'C': 106, '„Ç§': 107, 'Ôæâ': 108, 'Ôºπ': 109, '„Éº': 110, 'ÿ¨': 111, 'Ÿâ': 112, 'ÿ•': 113, 'ÿ¥': 114, 'ÿ°': 115, 'ÿ™': 116, 'ÿπ': 117, 'ŸÉ': 118, 'ÿ£': 119, 'ÿ§': 120, 'ÿ≥': 121, 'œÄ': 122, '≈º': 123, '—ö': 124, '—ü': 125, 'ìÇ∫': 126, 'Y': 127, 'L': 128, 'O': 129, 'N': 130, 'E': 131, 'D': 132, 'e': 133, 'k': 134, 't': 135, 'o': 136, '„Éé': 137, '„Éà': 138, '‰ªù': 139, '„Éü': 140, 'Âúü': 141, 'ÂΩ°': 142, '—º': 143, '\n': 144}
#Replace this with 'ItC' dict retrieved while learning
ITC = {0: ' ', 1: '–æ', 2: '–∞', 3: '–µ', 4: '—Ç', 5: '–∏', 6: '–Ω', 7: '—Å', 8: '–ª', 9: '—Ä', 10: '–≤', 11: '–∫', 12: '–º', 13: '–¥', 14: '—É', 15: '–ø', 16: '—å', 17: '—è', 18: ',', 19: '—ã', 20: '–±', 21: '—á', 22: '.', 23: '–π', 24: '–≥', 25: '–∑', 26: '—à', 27: '–∂', 28: '—Ö', 29: '—é', 30: '?', 31: '-', 32: '6', 33: '–ê', 34: '1', 35: '—Ü', 36: '–ö', 37: '–°', 38: '–ù', 39: '—ç', 40: '–í', 41: '–û', 42: '–ü', 43: '8', 44: '–ï', 45: '–¢', 46: ':', 47: '—â', 48: '–ò', 49: '–ú', 50: '9', 51: '0', 52: '–î', 53: '—ë', 54: '—Ñ', 55: '–õ', 56: '!', 57: '7', 58: '–†', 59: '3', 60: '2', 61: '–Ø', 62: '–£', 63: '–ì', 64: '–ë', 65: '5', 66: '4', 67: '–ß', 68: '–ó', 69: '–•', 70: '–®', 71: '–¨', 72: '–´', 73: '–≠', 74: '–ñ', 75: '–ô', 76: '—ä', 77: '–§', 78: '–Æ', 79: '–¶', 80: '–©', 81: '–Å', 82: '—ò', 83: 'Œû', 84: '–™', 85: 'Ÿä', 86: 'ŸÜ', 87: 'ŸÖ', 88: 'ÕÖ', 89: 'r', 90: '—ô', 91: '„ÉΩ', 92: 's', 93: 'p', 94: 'ŸÑ', 95: 'n', 96: 'a', 97: '„Ñõ', 98: '„Ñó', 99: '„Ñô', 100: 'ÿ±', 101: 'ÿß', 102: 'ŸÅ', 103: 'Ÿá', 104: '‡ΩÄ', 105: ' ñ', 106: 'C', 107: '„Ç§', 108: 'Ôæâ', 109: 'Ôºπ', 110: '„Éº', 111: 'ÿ¨', 112: 'Ÿâ', 113: 'ÿ•', 114: 'ÿ¥', 115: 'ÿ°', 116: 'ÿ™', 117: 'ÿπ', 118: 'ŸÉ', 119: 'ÿ£', 120: 'ÿ§', 121: 'ÿ≥', 122: 'œÄ', 123: '≈º', 124: '—ö', 125: '—ü', 126: 'ìÇ∫', 127: 'Y', 128: 'L', 129: 'O', 130: 'N', 131: 'E', 132: 'D', 133: 'e', 134: 'k', 135: 't', 136: 'o', 137: '„Éé', 138: '„Éà', 139: '‰ªù', 140: '„Éü', 141: 'Âúü', 142: 'ÂΩ°', 143: '—º', 144: '\n'}

#Replace this with prediction length you want
PRED_LEN = 130

file = open(os.path.join(__location__, 'model1000c.bin'), "rb")

class TextRNN(nn.Module):
    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):
        super(TextRNN, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.embedding_size = embedding_size
        self.n_layers = n_layers
        self.encoder = nn.Embedding(self.input_size, self.embedding_size)
        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)
        self.dropout = nn.Dropout(0.2)
        self.fc = nn.Linear(self.hidden_size, self.input_size)
    def forward(self, x, hidden):
        x = self.encoder(x).squeeze(2)
        out, (ht1, ct1) = self.lstm(x, hidden)
        out = self.dropout(out)
        x = self.fc(out)
        return x, (ht1, ct1)
    def init_hidden(self, batch_size=1):
        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),
               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))

def evaluate(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):
    hidden = model.init_hidden()
    idx_input = [char_to_idx[char] for char in start_text]
    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)
    predicted_text = start_text

    _, hidden = model(train, hidden)

    inp = train[-1].view(-1, 1, 1)
    for i in range(prediction_len):
        output, hidden = model(inp.to(device), hidden)
        output_logits = output.cpu().data.view(-1)
        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()
        top_index = np.random.choice(len(char_to_idx), p=p_next)
        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)
        predicted_char = idx_to_char[top_index]
        predicted_text += predicted_char
    return predicted_text

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
mod = torch.load(file, map_location=device)
mod.eval()

def textev():
    text = (evaluate(
            mod,
            CTI,
            ITC,
            temp=0.3,
            prediction_len=PRED_LEN,
            start_text=' '
            )
        )
    text = text.split(' ')
    text = text[1:-1]
    text = ' '.join(text)
    text = text.lower().capitalize()
    return text
if '-o' in sys.argv:
    print(textev())
elif '-p' in sys.argv:
    if '-c' in sys.argv:
        i = 0
        while(True):
            print(i)
            i += 1
            #text = (evaluate(mod, CTI, ITC, temp=0.3, prediction_len=PRED_LEN, start_text=' '))
            pic.draw(textev())
    else:
        pic.draw(textev())
